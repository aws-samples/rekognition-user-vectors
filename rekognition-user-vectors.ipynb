{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d45dc96e-8d47-479d-9d98-0a01ab7f01f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Improving Accuracy of Rekognition Face Search with User Vectors\n",
    "### Face search of images against a collection of users faces\n",
    "![results](./results.jpeg)\n",
    "\n",
    "---\n",
    "This notebook is an end to end example how to build a face search system using [Amazon Rekognition](https://aws.amazon.com/rekognition/).<br>\n",
    "Amazon Rekognition enables you to achieve very high face search accuracy with a single face image. In some cases, you can use multiple images of the same person's face to create user vectors and improve accuracy even further. This is especially helpful when images have variations in lighting, poses, and appearances.<br>\n",
    "\n",
    "This will guide you through creating a collection, storing face vectors in that collection, aggregating those face vectors into user vectors, and then comparing the results of searching against those individual face vectors and user vectors.\n",
    "\n",
    "In June 2023, [AWS launched user vectors, a new capability that significantly improves face search accuracy](https://aws.amazon.com/about-aws/whats-new/2023/06/amazon-rekognition-face-search-accuracy-user-vectors/) by leveraging multiple face images of a user. Now, customers can create user vectors, which aggregate multiple face vectors of the same user. User vectors offer higher face search accuracy with more robust depictions, as they contain varying degrees of lighting, sharpness, pose, appearance, etc. This improves the accuracy compared to searching aginst individual face vectors.\n",
    "\n",
    "\n",
    "\n",
    "**NOTE: You can run this notebook in SageMaker Studio, JupyterLab, or on your local machine**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b477b2-6273-4be1-ba20-f09cadaed2ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Contents\n",
    "\n",
    "1. [Installation](#Installation)\n",
    "2. [Environment Creation](#Environment-Creation)\n",
    "3. [Face search of image against a collection of individual face vectors](#Face-search-of-image-against-a-collection-of-individual-face-vectors)\n",
    "4. [Face search of image against a collection of user vectors](#Face-search-of-image-against-a-collection-of-user-vectors)\n",
    "5. [Cleanup](#Cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78824d46-2360-4e35-9731-72d910a2a457",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4544b64-95f7-423a-8d45-eea0dce4f0a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install Pillow --upgrade\n",
    "!pip3 install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4440d1d9-3ee5-4ada-807a-51a636b878ea",
   "metadata": {},
   "source": [
    "### Permissions required to run this notebook\n",
    "You are required to have permission to access the Rekognition API and to access an S3 bucket for storing the images.<br>\n",
    "Add this minimal policy to your IAM Role to enable the execution of the code outlined in this notebook.<br>\n",
    "Make sure to replace <i>your-bucket-name</i> with the real bucket name.\n",
    "```\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"RekognitionPermissions\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"rekognition:CreateCollection\",\n",
    "                \"rekognition:DeleteCollection\",\n",
    "                \"rekognition:CreateUser\",\n",
    "                \"rekognition:IndexFaces\",\n",
    "                \"rekognition:DetectFaces\",\n",
    "                \"rekognition:AssociateFaces\",\n",
    "                \"rekognition:SearchUsersByImage\",\n",
    "                \"rekognition:SearchFacesByImage\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        },\n",
    "        {\n",
    "            \"Sid\": \"S3BucketPermissions\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::your-bucket-name/*\",\n",
    "                \"arn:aws:s3:::your-bucket-name\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982c5513-b7e5-4593-bdeb-43f0f2c66f86",
   "metadata": {},
   "source": [
    "# Environment Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f2650a-a050-4aba-b846-f8e35f38086d",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this section we will create our environment resources.<br>\n",
    "The steps are:\n",
    "* Upload the images to S3 bucket\n",
    "* Create a Rekognition collection\n",
    "* Populate our collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d539a8-23a7-4daf-b6e3-eb22fb6ba3c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bucket where we will store our images\n",
    "bucket = '<replace_with_your_bucket>'\n",
    "\n",
    "# The Rekognition collection id\n",
    "collection_id = \"faces-collection\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9c053d-e284-42e5-a6d4-27aa6911f03a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Upload the images folder to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be26dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "def upload_to_s3(path, bucket):\n",
    "    s3 = boto3.resource('s3')\n",
    "    folder_name = os.path.basename(os.path.normpath(path))\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            local_path = os.path.join(root, file)\n",
    "            s3_key = os.path.relpath(local_path, path).replace(\"\\\\\", \"/\")\n",
    "            s3_key = os.path.join(folder_name, s3_key)\n",
    "            s3.Bucket(bucket).upload_file(local_path, s3_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f369c8eb-bcfb-4a26-b0cc-cccae314c633",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_to_s3(path='./images', bucket=bucket)\n",
    "print(f\"Uploaded images to: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46775aa1-4b6b-42d1-b962-293f23e64802",
   "metadata": {},
   "source": [
    "### Define helper functions\n",
    "* create_collection - create a new collection\n",
    "* delete_collection - delete a collection\n",
    "* create_user - create a new user in a collection\n",
    "* add_faces_to_collection - add faces to collection\n",
    "* associate_faces - associate face_ids to a user in a collection\n",
    "* get_subdirs - get all sub directories under s3 prefix\n",
    "* get_files - get all files under s3 prefix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e009b00-8ac3-409d-94da-7a9e20b01832",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pygmentize -g helpers.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edc63f4-5dac-4a0c-946c-89aaff0cf237",
   "metadata": {},
   "source": [
    "### Create Rekognition Collection for the faces and users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5d0678-bd9c-49f2-818a-c9e89f2c23ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import helpers\n",
    "helpers.create_collection(collection_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bef00a",
   "metadata": {},
   "source": [
    "### Populate our collection\n",
    "Our S3 bucket has a directory for each user that stores their images<br>\n",
    "We will:\n",
    "* Create users per each user directory under S3<br>\n",
    "* Get the face_id from each image and add it to the collection as individual face vector<br>\n",
    "* Associate the face_ids to the appropriate user vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f211b2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'images/'\n",
    "\n",
    "# Get all the users directories from s3 containing the images\n",
    "folder_list = helpers.get_subdirs(bucket, prefix)\n",
    "print(f\"Found users folders: {folder_list}\")\n",
    "print()\n",
    "\n",
    "for user_id in folder_list:\n",
    "    face_ids = []\n",
    "    helpers.create_user(collection_id, user_id)\n",
    "    # Get all files per user under the s3 user directory\n",
    "    images = helpers.get_files(bucket, prefix + user_id + \"/\")\n",
    "    print (f\"Found images={images} for {user_id}\")\n",
    "    for image in images:\n",
    "        face_id = helpers.add_faces_to_collection(bucket, image, collection_id)\n",
    "        face_ids.append(face_id)\n",
    "    helpers.associate_faces(collection_id, user_id, face_ids)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd15f785",
   "metadata": {},
   "source": [
    "We would like to take a new photo with multiple people and attempt to match their\n",
    "faces against our collection, first against the individual face vectors and then against the user vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14024445",
   "metadata": {},
   "source": [
    "# Face search of image against a collection of individual face vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdc8f4b",
   "metadata": {},
   "source": [
    "In this section we will take a new image containing multiple faces and attempt to match those faces against **individual faces** in our collection.<br>\n",
    "For this purpose we will use the <i>detect_users.detect_faces_in_image</i> method.<br>\n",
    "\n",
    "The function detects faces in an image and for each face it will:\n",
    "* Print its bounding box location\n",
    "* Check if such face exist in our collection and print the user or 'Unknown'\n",
    "* Print the similarity score\n",
    "\n",
    "The logic:\n",
    "1. We call Amazon Rekognition [DetectFaces](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_DetectFaces.html) api per our image to detect and get all faces in the image and obtain their bounding box locations within the image\n",
    "2. For each detected face in the image, we crop the face based on its location and send the cropped face image to the Amazon Rekognition [SearchFacesByImage](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_SearchFacesByImage.html) api. This function gets an image file and compare it faces against individual faces in our collection and return the faces that matches.\n",
    "<i>SearchFacesByImage</i> returns the biggest face in an input image. Therefore, if the image contains multiple faces, we need to crop each face and send it individually to the method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0360c2f3",
   "metadata": {},
   "source": [
    "We will use a similarity score threshold of 99%, which is a common setting for identity verification (IDV)\n",
    "use cases.\n",
    "<br/>\n",
    "Using a threshold of 99% Dr. Werner Vogels should be flagged as Unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2558bb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detect_users\n",
    "from IPython.display import display\n",
    "\n",
    "# The image we would like to match faces against our internal collection.\n",
    "file_key = prefix + \"photo.jpeg\"\n",
    "\n",
    "img = detect_users.detect_faces_in_image(\n",
    "    bucket, \n",
    "    file_key, \n",
    "    collection_id, \n",
    "    threshold=99\n",
    ")\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39538ccd",
   "metadata": {},
   "source": [
    "Let's try to lower the threshold to 90% and run again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859c52c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detect_users\n",
    "from IPython.display import display\n",
    "\n",
    "# The image we would like to match faces against our internal collection.\n",
    "file_key = prefix + \"photo.jpeg\"\n",
    "\n",
    "img = detect_users.detect_faces_in_image(\n",
    "    bucket, \n",
    "    file_key, \n",
    "    collection_id, \n",
    "    threshold=90\n",
    ")\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec99875b",
   "metadata": {},
   "source": [
    "Let's check if we can get the similarity score above our defined threshold by using user vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f681d8-4df6-4794-b848-211241c545be",
   "metadata": {},
   "source": [
    "# Face search of image against a collection of user vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad4f360",
   "metadata": {},
   "source": [
    "In this section we will take an image containing multiple faces and attempt to match those faces against our collection using **User Vectors**<br>\n",
    "For this purpose we will use the <i>detect_users.detect_users_in_image</i> method<br>\n",
    "\n",
    "The function detects faces in an image and for each face it will:\n",
    "* Print its bounding box location\n",
    "* Check if such user face exist in our collection and print the user or 'Unknown'\n",
    "* Print the similarity score\n",
    "\n",
    "The logic:\n",
    "1. We call Amazon Rekognition [DetectFaces](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_DetectFaces.html) api per our image to detect and get all faces in the image and obtain their bounding box locations within the image\n",
    "2. For each detected face in the image, we crop the face based on its location and send the cropped face image to the Amazon Rekognition [SearchUsersByImage](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_SearchUsersByImage.html) api.\n",
    "<i>SearchUsersByImage</i> returns the biggest face in an input image. Therefore, if the image contains multiple faces, we need to crop each face and send it individually to the method\n",
    "\n",
    "Here is the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757bc574-7299-4fd6-87b6-b3dd0f607f55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pygmentize -g detect_users.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c18b27-c299-4063-aa89-ad4ee26ef1c6",
   "metadata": {},
   "source": [
    "### Find users in an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c048740d-fab1-421f-b981-4ef1f7bb1029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import detect_users\n",
    "from IPython.display import display\n",
    "\n",
    "# The image we would like to match faces against our internal collection.\n",
    "file_key = prefix + \"photo.jpeg\"\n",
    "\n",
    "img = detect_users.detect_users_in_image(\n",
    "    bucket, \n",
    "    file_key, \n",
    "    collection_id, \n",
    "    threshold=99\n",
    ")\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d4c33a-7d1e-4b8b-b9d8-7c0bd19a0b38",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96fc97a-1513-4c24-8c8c-0c464e5a9062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "helpers.delete_collection(collection_id)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
